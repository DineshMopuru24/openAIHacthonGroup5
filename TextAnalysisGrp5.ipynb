{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install azure-cognitiveservices-vision-computervision azure-ai-textanalytics pillow\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-cognitiveservices-vision-computervision in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.9.0)\nRequirement already satisfied: azure-ai-textanalytics in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (5.3.0)\nRequirement already satisfied: pillow in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (9.2.0)\nRequirement already satisfied: azure-common~=1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-cognitiveservices-vision-computervision) (1.1.28)\nRequirement already satisfied: msrest>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-cognitiveservices-vision-computervision) (0.7.1)\nRequirement already satisfied: azure-core<2.0.0,>=1.24.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-textanalytics) (1.26.4)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-textanalytics) (4.11.0)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-ai-textanalytics) (0.6.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2022.9.24)\nRequirement already satisfied: requests-oauthlib>=0.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.3.1)\nRequirement already satisfied: requests~=2.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (2.31.0)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.2.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-vision-computervision) (3.4)\n"
        }
      ],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "from PIL import Image\n",
        " \n",
        "# Add your Computer Vision subscription key and endpoint\n",
        "subscription_key = \"\"\n",
        "endpoint = \"https://openaicomvision.cognitiveservices.azure.com/\"\n",
        " \n",
        "# Create a client\n",
        "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "gather": {
          "logged": 1715768704149
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        " \n",
        "# Open an image file\n",
        "image_path = \"handwriten_french.jpg\"\n",
        "with open(image_path, \"rb\") as image_stream:\n",
        "    # Perform OCR (Optical Character Recognition) on the image\n",
        "    ocr_result = computervision_client.read_in_stream(image_stream, raw=True)\n",
        " \n",
        "# Extract text from the result\n",
        "operation_location = ocr_result.headers[\"Operation-Location\"]\n",
        "operation_id = operation_location.split(\"/\")[-1]\n",
        " \n",
        "# Get the result\n",
        "result = computervision_client.get_read_result(operation_id)\n",
        "while result.status not in [\"succeeded\", \"failed\"]:\n",
        "    result = computervision_client.get_read_result(operation_id)\n",
        " \n",
        "# Extract lines of text\n",
        "lines = []\n",
        "if result.status == \"succeeded\":\n",
        "    for text_result in result.analyze_result.read_results:\n",
        "        for line in text_result.lines:\n",
        "            lines.append(line.text)\n",
        " \n",
        "# Join lines to form the complete text\n",
        "handwritten_text = \"\\n\".join(lines)\n",
        "print(handwritten_text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Old French School\nJ'ai voulu approcher l'écriture telle qu'on la\npratiquait encore dans les années 60 dans mon\nécole primaire à Suilly la Tour ( Nievre). La plume\nétait toujours obligatoire en classe même si le style\nà bille s'était déjà imposé partout ailleurs. Il faudra\nle tourbillon de 1968 pour la faire disparaître avec\nles taches, les pages arrachées et les doigts violets.\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715768705854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        " \n",
        "# Add your Text Analytics subscription key and endpoint\n",
        "text_analytics_key = \"\"\n",
        "text_analytics_endpoint = \"https://langtrain123.cognitiveservices.azure.com/\"\n",
        " \n",
        "# Create a client\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=text_analytics_endpoint, credential=AzureKeyCredential(text_analytics_key))"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715768706247
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: requests in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (2.31.0)\r\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests) (3.4)\r\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests) (2022.9.24)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests) (1.26.16)\r\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests) (3.1.0)\r\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        " \n",
        "# Azure Translator credentials\n",
        "translator_key = \"\"\n",
        "translator_endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
        "translator_location = \"eastus\"\n",
        " \n",
        "# Function to translate text\n",
        "def translate_text(text, target_language=\"en\"):\n",
        "    path = '/translate'\n",
        "    constructed_url = translator_endpoint + path\n",
        " \n",
        "    headers = {\n",
        "        'Ocp-Apim-Subscription-Key': translator_key,\n",
        "        'Ocp-Apim-Subscription-Region': translator_location,\n",
        "        'Content-type': 'application/json'\n",
        "    }\n",
        "    params = {\n",
        "        'api-version': '3.0',\n",
        "        'to': target_language\n",
        "    }\n",
        "    body = [{\n",
        "        'text': text\n",
        "    }]\n",
        "    request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
        "    response = request.json()\n",
        "    return response[0]['translations'][0]['text']"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715768710438
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Sentiment Analysis\n",
        "def analyze_text(text):\n",
        "    response = text_analytics_client.analyze_sentiment(documents=[text])[0]\n",
        "    print(f\"Sentiment: {response.sentiment}\")\n",
        "    print(f\"Positive score: {response.confidence_scores.positive}\")\n",
        "    print(f\"Neutral score: {response.confidence_scores.neutral}\")\n",
        "    print(f\"Negative score: {response.confidence_scores.negative}\")\n",
        " \n",
        "# Example: Key Phrase Extraction\n",
        "def extract_key_phrases(text):\n",
        "    response = text_analytics_client.extract_key_phrases(documents=[text])[0]\n",
        "    print(\"Key Phrases:\")\n",
        "    for phrase in response.key_phrases:\n",
        "        print(f\"- {phrase}\")\n",
        "def detect_language(text):\n",
        "    response = text_analytics_client.detect_language(documents=[text])[0]\n",
        "    print(f\"\\nDetected Language: {response.primary_language.name}\")\n",
        "    print(f\"ISO 6391 Code: {response.primary_language.iso6391_name}\")\n",
        "    print(f\"Confidence Score: {response.primary_language.confidence_score}\")\n",
        "\n",
        "# Detect language of the handwritten text\n",
        "detect_language(handwritten_text)\n",
        "\n",
        "\n",
        "# Analyze the handwritten text\n",
        "analyze_text(handwritten_text)\n",
        "extract_key_phrases(handwritten_text)\n",
        "\n",
        "if detect_language != \"en\":\n",
        "    translated_text = translate_text(handwritten_text, \"en\")\n",
        "    print(f\"\\nTranslated Text:\\n{translated_text}\")\n",
        "else:\n",
        "    translated_text = handwritten_text\n",
        " \n",
        "# Perform sentiment analysis and key phrase extraction on the translated text\n",
        "analyze_text(translated_text)\n",
        "extract_key_phrases(translated_text)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\nDetected Language: French\nISO 6391 Code: fr\nConfidence Score: 1.0\nSentiment: mixed\nPositive score: 0.33\nNeutral score: 0.38\nNegative score: 0.29\nKey Phrases:\n- Old French School\n- Suilly la Tour\n- La plume\n- années\n- école primaire\n- doigts violets\n- écriture\n- Nievre\n- classe\n- style\n- bille\n- tourbillon\n- taches\n- pages\n- 60\n\nTranslated Text:\nOld French School\nI wanted to approach writing as it is\nwas still practicing in the 60s in my\nprimary school at Suilly la Tour (Nievre). The pen\nwas still mandatory in the classroom even though the style\nhad already established itself everywhere else. It will be necessary\ntourbillon of 1968 to make it disappear with\nthe spots, the torn pages and the purple fingers.\nSentiment: negative\nPositive score: 0.01\nNeutral score: 0.27\nNegative score: 0.72\nKey Phrases:\n- Suilly la Tour\n- Old French School\n- primary school\n- torn pages\n- purple fingers\n- writing\n- 60s\n- Nievre\n- pen\n- classroom\n- style\n- tourbillon\n- spots\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1715768712785
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
